{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import hashlib\n",
    "import requests\n",
    "import csv\n",
    "from qnt.output_avro import convert_avro_record_to_output, convert_output_to_avro_record\n",
    "from qnt.data import sort_and_crop_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed API avro schema\n",
    "feed_api = \"http://quantnet-ai.ru:9090/statan/feed/avro/\"\n",
    "\n",
    "# Request authorization header (PUT YOUR PERSONAL TOKEN HERE)\n",
    "feed_api_header = \"YOUR ACCESS TOKEN\"\n",
    "\n",
    "# Blockchain public API which should return all information about verification transactions and dates\n",
    "blockchain_api = \"http://192.168.122.241:5300/getAllData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fetching data from Blockchain API\n",
    "blockchain_api_data = requests.get(blockchain_api).json()[\"result\"]\n",
    "\n",
    "# Creating empty arrays for storing blockchain data\n",
    "# Blockchain transactions hashes\n",
    "txs = []\n",
    "\n",
    "# Sha256 root hashes generated from daily data\n",
    "roots = []\n",
    "\n",
    "# CSV texts of submisions (submission_id, daily_output_avro_hash)\n",
    "csv_texts = []\n",
    "\n",
    "# Dates of each csv text, fetched from the Statan API\n",
    "dates = []\n",
    "\n",
    "# Sorting data into arrays by type\n",
    "for data in blockchain_api_data:\n",
    "    txs.append(data[\"tx\"])\n",
    "    roots.append(data[\"root\"])\n",
    "    csv_texts.append(data[\"data\"])\n",
    "    dates.append(data[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing the daily data with a sha256 algorithm, and compare it with provided data from API \n",
    "def compare_daily_data_hash_with_generated_hash(root, data):\n",
    "    hash = hashlib.sha256(data.encode('utf-8')).hexdigest()\n",
    "    return bool(True) if hash == root else bool(False)\n",
    "\n",
    "# verifieng all dates and hashes\n",
    "# as an argument need to pass root hashes and csv texts\n",
    "# the lengths of arrays should be equal\n",
    "def compare_root_hashes_with_daily_data_hashes(roots, csv_texts):\n",
    "    if (len(roots) == len(csv_texts)):\n",
    "        i = 0\n",
    "        while i < len(csv_texts):\n",
    "            is_valid = compare_daily_data_hash_with_generated_hash(roots[i], csv_texts[i])\n",
    "            result = \"the same\" if is_valid else \"different\"\n",
    "            print(\"The hash of csv data and root from \" + dates[i] + \" is \" + result)\n",
    "            i += 1\n",
    "    else:\n",
    "        print(\"The lengths should be equal!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fetching avro/binary data by submission_id from Feed API\n",
    "def get_submision_output(submission_id):    \n",
    "    output = requests.get(feed_api + submission_id, headers={\"Authorization\" : feed_api_header})\n",
    "    output = convert_avro_record_to_output(output.content)\n",
    "    return output\n",
    "\n",
    "# Generate the sha256 hash by submission_id for certain date\n",
    "def generate_output_hash(submission_id, date):\n",
    "    xarr = get_submision_output(submission_id)\n",
    "    s = xarr.loc[date:date]\n",
    "    s = sort_and_crop_output(s)\n",
    "    avs = convert_output_to_avro_record(s)\n",
    "    hash = hashlib.sha256(avs).hexdigest()\n",
    "    return hash\n",
    "\n",
    "# Generate the sha256 hash from output and verify with daily output hash\n",
    "def verify_outputs_per_date(date):\n",
    "    data = csv_texts[dates.index(date)]\n",
    "    csv_data = csv.DictReader(data.splitlines())\n",
    "    for row in csv_data:\n",
    "        submission_id = row[\"submission_id\"]\n",
    "        avro_hash = row[\"daily_output_avro_hash\"]\n",
    "        generated_hash = generate_output_hash(submission_id, date)\n",
    "        result = \"valid\" if generated_hash == avro_hash else \"invalid\"\n",
    "        print(\"ID \" + submission_id + \" at \" + date + \" is \" + result)\n",
    "\n",
    "# Verify all outputs from all dates\n",
    "def verify_outputs_all_dates(dates):\n",
    "    for date in dates:\n",
    "        verify_outputs_per_date(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of blockchain based roots and daily data\n",
    "compare_root_hashes_with_daily_data_hashes(roots, csv_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verification of the generated sha256 hash of the daily data and provided sha256 hashes\n",
    "verify_outputs_all_dates(dates)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
